{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f894ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92acf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2405cd",
   "metadata": {},
   "source": [
    "### Lyric preprocessing & Sentiment annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc2234",
   "metadata": {},
   "source": [
    "Read data from local csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a16cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"songs_with_lyrics_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70926a81",
   "metadata": {},
   "source": [
    "Clean lyrics from the following:\n",
    "* \\n\n",
    "* [something]\n",
    "\n",
    "Also explored invalid urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da130194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics):\n",
    "    # Remove text within brackets\n",
    "    cleaned_lyrics = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \"\", lyrics)\n",
    "\n",
    "    # Capitalize the first letter of each line\n",
    "    cleaned_lyrics = cleaned_lyrics.replace('\\n', \" \")\n",
    "    cleaned_lyrics = cleaned_lyrics.strip(\" \")\n",
    "\n",
    "    return cleaned_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8d39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to your DataFrame\n",
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c57ec1",
   "metadata": {},
   "source": [
    "After data exploration, we realize that some extra and more custom cleaning is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2da8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this url is not the url of a song\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Scopey-almost-every-album-ive-listened-to-lyrics'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Hossein-amini-drive-annotated'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Genius-valentines-day-playlists-lyrics'].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c2fa3",
   "metadata": {},
   "source": [
    "Label songs based on their lyric sentiments.\n",
    "\n",
    "Used textblob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47ba208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sentiment analysis using TextBlob\n",
    "def get_sentiment(lyrics):\n",
    "    try:\n",
    "        blob = TextBlob(lyrics)\n",
    "        # TextBlob returns polarity and subjectivity, you can use just polarity for a simple positive/negative/neutral sentiment\n",
    "        polarity = blob.sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            return \"Positive\"\n",
    "        elif polarity < 0:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing lyrics: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_lyrics(lyric):\n",
    "    cleaned_lyrics = re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6303e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.8 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['sentiment'] = df['lyrics'].apply(lambda lyrics: get_sentiment(lyrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aab5e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>playlist</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>1cQld05IcUDw3RCFt7uymW</td>\n",
       "      <td>Be The One</td>\n",
       "      <td>5lVNSw2GPci8kebrAQpZqU</td>\n",
       "      <td>Eli Brown</td>\n",
       "      <td>75</td>\n",
       "      <td>['2zMZv11a981pTJORORVKbz', '0LJk5MTU4Jn2AlgLTd...</td>\n",
       "      <td>https://genius.com/Eli-brown-be-the-one-lyrics</td>\n",
       "      <td>I know that you're lonely, want someone to hol...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9099</th>\n",
       "      <td>3EraWxocoFkg6PTjxII85U</td>\n",
       "      <td>Too Strange for the Circus</td>\n",
       "      <td>21YCHE0ZFflbHVTsyrCpgh</td>\n",
       "      <td>Debbii Dawson</td>\n",
       "      <td>47</td>\n",
       "      <td>['37i9dQZF1DX0MLFaUdXnjA']</td>\n",
       "      <td>https://genius.com/Debbii-dawson-too-strange-f...</td>\n",
       "      <td>Head spins, tooths fall Heartache in the bathr...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2I28t30wCQQDmR9do0knxp</td>\n",
       "      <td>Closer to You</td>\n",
       "      <td>2MjEBovZ1pZmzlQJCQjgS9</td>\n",
       "      <td>Christian McKinney</td>\n",
       "      <td>28</td>\n",
       "      <td>['2fyE3mKj0FoQ1klcyRb9yH']</td>\n",
       "      <td>https://genius.com/Christian-mckinney-closer-t...</td>\n",
       "      <td>Creator of the universe Lord you take my breat...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>0Ut7NNgAIlY9RGeXIvNfXF</td>\n",
       "      <td>Enemy Brain</td>\n",
       "      <td>2BQWHuvxG4kMYnfghdaCIy</td>\n",
       "      <td>Fox Stevenson</td>\n",
       "      <td>43</td>\n",
       "      <td>['37i9dQZF1DWTfrr8pte1rT']</td>\n",
       "      <td>https://genius.com/Fox-stevenson-enemy-brain-l...</td>\n",
       "      <td>Just another day in this hell world, hey I don...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>3wjD3Ufjll7UKrEDPdGuX3</td>\n",
       "      <td>Maybe It Was Memphis</td>\n",
       "      <td>1SX44N5qjWuFcCK8WTO0c6</td>\n",
       "      <td>Pam Tillis</td>\n",
       "      <td>61</td>\n",
       "      <td>['3NKthdgxid2S9fHhN54Vp3']</td>\n",
       "      <td>https://genius.com/Pam-tillis-maybe-it-was-mem...</td>\n",
       "      <td>Looking at you through a misty moonlight Katy ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>7MRyJPksH3G2cXHN8UKYzP</td>\n",
       "      <td>American Girl</td>\n",
       "      <td>4tX2TplrkIP4v05BNC903e</td>\n",
       "      <td>Tom Petty and the Heartbreakers</td>\n",
       "      <td>74</td>\n",
       "      <td>['2lk6445GUpENJLdDyJFMHJ', '37i9dQZF1EIcVkEtbz...</td>\n",
       "      <td>https://genius.com/Tom-petty-and-the-heartbrea...</td>\n",
       "      <td>Well, she was an American girl Raised on promi...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>1UaHt8XVYOmbvc8MEiVdfI</td>\n",
       "      <td>I DONT WANNA BE MYSELF</td>\n",
       "      <td>6YqsG5YZEACC698v66oGMm</td>\n",
       "      <td>cloverscars</td>\n",
       "      <td>44</td>\n",
       "      <td>['4PWQV9dQpT7As9OTZBqrR8']</td>\n",
       "      <td>https://genius.com/Cloverscars-i-dont-wanna-be...</td>\n",
       "      <td>I don't wanna be myself I ain't too happy with...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8858</th>\n",
       "      <td>3H3r2nKWa3Yk5gt8xgmsEt</td>\n",
       "      <td>This City</td>\n",
       "      <td>6L1XC7NrmgWRlwAeLJvVtA</td>\n",
       "      <td>Sam Fischer</td>\n",
       "      <td>78</td>\n",
       "      <td>['0hEjaQYvUZKzV3JGzxgcwx', '6UQ4WyqgIFEJe95T02...</td>\n",
       "      <td>https://genius.com/Sam-fischer-this-city-lyrics</td>\n",
       "      <td>I've been seeing lonely people in crowded room...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>3ihIZrJreMJPjQdNLrEXnP</td>\n",
       "      <td>In A Minute</td>\n",
       "      <td>5f7VJjfbwm532GiveGC0ZK</td>\n",
       "      <td>Lil Baby</td>\n",
       "      <td>68</td>\n",
       "      <td>['2ktsU5qFJ4ugmC8SvwXdN2']</td>\n",
       "      <td>https://genius.com/Lil-baby-in-a-minute-lyrics</td>\n",
       "      <td>( Damn, Kai, you goin' crazy )  I be in the lo...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>2xSC2Tvr2I44VZmCXg60dW</td>\n",
       "      <td>Had Enough</td>\n",
       "      <td>1kF0gYnHLUJvFuPdoowO02</td>\n",
       "      <td>Lower Than Atlantis</td>\n",
       "      <td>40</td>\n",
       "      <td>['53mEsGlH3Ou6RFpa77T8yo']</td>\n",
       "      <td>https://genius.com/Lower-than-atlantis-had-eno...</td>\n",
       "      <td>I hate everyone that I meet But I'm getting be...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     song_id                   song_name  \\\n",
       "693   1cQld05IcUDw3RCFt7uymW                  Be The One   \n",
       "9099  3EraWxocoFkg6PTjxII85U  Too Strange for the Circus   \n",
       "1577  2I28t30wCQQDmR9do0knxp               Closer to You   \n",
       "2326  0Ut7NNgAIlY9RGeXIvNfXF                 Enemy Brain   \n",
       "5161  3wjD3Ufjll7UKrEDPdGuX3        Maybe It Was Memphis   \n",
       "405   7MRyJPksH3G2cXHN8UKYzP               American Girl   \n",
       "3772  1UaHt8XVYOmbvc8MEiVdfI      I DONT WANNA BE MYSELF   \n",
       "8858  3H3r2nKWa3Yk5gt8xgmsEt                   This City   \n",
       "4132  3ihIZrJreMJPjQdNLrEXnP                 In A Minute   \n",
       "3165  2xSC2Tvr2I44VZmCXg60dW                  Had Enough   \n",
       "\n",
       "                   artist_id                      artist_name  popularity  \\\n",
       "693   5lVNSw2GPci8kebrAQpZqU                        Eli Brown          75   \n",
       "9099  21YCHE0ZFflbHVTsyrCpgh                    Debbii Dawson          47   \n",
       "1577  2MjEBovZ1pZmzlQJCQjgS9               Christian McKinney          28   \n",
       "2326  2BQWHuvxG4kMYnfghdaCIy                    Fox Stevenson          43   \n",
       "5161  1SX44N5qjWuFcCK8WTO0c6                       Pam Tillis          61   \n",
       "405   4tX2TplrkIP4v05BNC903e  Tom Petty and the Heartbreakers          74   \n",
       "3772  6YqsG5YZEACC698v66oGMm                      cloverscars          44   \n",
       "8858  6L1XC7NrmgWRlwAeLJvVtA                      Sam Fischer          78   \n",
       "4132  5f7VJjfbwm532GiveGC0ZK                         Lil Baby          68   \n",
       "3165  1kF0gYnHLUJvFuPdoowO02              Lower Than Atlantis          40   \n",
       "\n",
       "                                               playlist  \\\n",
       "693   ['2zMZv11a981pTJORORVKbz', '0LJk5MTU4Jn2AlgLTd...   \n",
       "9099                         ['37i9dQZF1DX0MLFaUdXnjA']   \n",
       "1577                         ['2fyE3mKj0FoQ1klcyRb9yH']   \n",
       "2326                         ['37i9dQZF1DWTfrr8pte1rT']   \n",
       "5161                         ['3NKthdgxid2S9fHhN54Vp3']   \n",
       "405   ['2lk6445GUpENJLdDyJFMHJ', '37i9dQZF1EIcVkEtbz...   \n",
       "3772                         ['4PWQV9dQpT7As9OTZBqrR8']   \n",
       "8858  ['0hEjaQYvUZKzV3JGzxgcwx', '6UQ4WyqgIFEJe95T02...   \n",
       "4132                         ['2ktsU5qFJ4ugmC8SvwXdN2']   \n",
       "3165                         ['53mEsGlH3Ou6RFpa77T8yo']   \n",
       "\n",
       "                                             lyrics_url  \\\n",
       "693      https://genius.com/Eli-brown-be-the-one-lyrics   \n",
       "9099  https://genius.com/Debbii-dawson-too-strange-f...   \n",
       "1577  https://genius.com/Christian-mckinney-closer-t...   \n",
       "2326  https://genius.com/Fox-stevenson-enemy-brain-l...   \n",
       "5161  https://genius.com/Pam-tillis-maybe-it-was-mem...   \n",
       "405   https://genius.com/Tom-petty-and-the-heartbrea...   \n",
       "3772  https://genius.com/Cloverscars-i-dont-wanna-be...   \n",
       "8858    https://genius.com/Sam-fischer-this-city-lyrics   \n",
       "4132     https://genius.com/Lil-baby-in-a-minute-lyrics   \n",
       "3165  https://genius.com/Lower-than-atlantis-had-eno...   \n",
       "\n",
       "                                                 lyrics language sentiment  \n",
       "693   I know that you're lonely, want someone to hol...       en  Negative  \n",
       "9099  Head spins, tooths fall Heartache in the bathr...       en  Negative  \n",
       "1577  Creator of the universe Lord you take my breat...       en  Positive  \n",
       "2326  Just another day in this hell world, hey I don...       en  Positive  \n",
       "5161  Looking at you through a misty moonlight Katy ...       en  Positive  \n",
       "405   Well, she was an American girl Raised on promi...       en  Positive  \n",
       "3772  I don't wanna be myself I ain't too happy with...       en  Positive  \n",
       "8858  I've been seeing lonely people in crowded room...       en  Positive  \n",
       "4132  ( Damn, Kai, you goin' crazy )  I be in the lo...       en  Positive  \n",
       "3165  I hate everyone that I meet But I'm getting be...       en  Negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c1d50",
   "metadata": {},
   "source": [
    "#### Lyric descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2beec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric descriptives\n",
      "--------------------------\n",
      "Number of songs: 10514\n",
      "Average number of characters in a song's lyrics: 1895.2707818147233\n",
      "Average number of words in a song's lyrics: 376.53671295415637\n"
     ]
    }
   ],
   "source": [
    "rows = len(df)\n",
    "average_length = df['lyrics'].str.len().mean()\n",
    "average_words = df['lyrics'].apply(lambda x: len(x.split())).mean()\n",
    "print(\"Lyric descriptives\")\n",
    "print(\"--------------------------\")\n",
    "print(f\"Number of songs: {rows}\")\n",
    "print(f\"Average number of characters in a song's lyrics: {average_length}\")\n",
    "print(f\"Average number of words in a song's lyrics: {average_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e48745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.12992200875024%\n",
      "Precentage of positive labels: 67.26269735590641%\n",
      "Precentage of neutral labels: 1.6073806353433517%\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df[df['sentiment']=='Negative'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df[df['sentiment']=='Positive'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of neutral labels: {len(df[df['sentiment']=='Neutral'])/len(df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2bf1d",
   "metadata": {},
   "source": [
    "### Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976a7bc",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Preprocessing with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['lyrics'])\n",
    "y = df['encoded_sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d128cf",
   "metadata": {},
   "source": [
    "#### Balancing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f03861e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The {'neutral', 'negative'} target class is/are not present in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39msampling_strategy)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the training data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train_smote, y_train_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:84\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m     82\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m     90\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     92\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:534\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28msorted\u001b[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[1;32m--> 534\u001b[0m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_dict(sampling_strategy, y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    535\u001b[0m     )\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type)\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    539\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:289\u001b[0m, in \u001b[0;36m_sampling_strategy_dict\u001b[1;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[0;32m    285\u001b[0m set_diff_sampling_strategy_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sampling_strategy\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m    286\u001b[0m     target_stats\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    287\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(set_diff_sampling_strategy_target) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_diff_sampling_strategy_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m target class is/are not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresent in the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# check that there is no negative number\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(n_samples \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "\u001b[1;31mValueError\u001b[0m: The {'neutral', 'negative'} target class is/are not present in the data."
     ]
    }
   ],
   "source": [
    "# Initialize SMOTE\n",
    "sampling_strategy = {0: int(y_train.sum() * 0.5), 'neutral': int(y_train.sum() * 0.5)}  # Adjust these ratios as needed\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed702783",
   "metadata": {},
   "source": [
    "**Algorithm selectio**\n",
    "\n",
    "We keep in mind the computational resources needed for the algorithms. Maybe we don't end up with the stringest model, but we aim for the most feasibly reliable one.\n",
    "\n",
    "| Algorithm | Pros | Cons |\n",
    "|-----------|------|------|\n",
    "| **SVM (Support Vector Machine)** | - Effective in high-dimensional spaces<br> - Works well with a clear margin of separation<br> - Less prone to overfitting | - Not suitable for very large datasets<br> - Requires feature scaling<br> - Can be less effective with overlapping classes |\n",
    "| **Naive Bayes** | - Fast and efficient<br> - Works well with high-dimensional data<br> - Effective for text classification | - Based on the assumption of feature independence<br> - Can be outperformed by more complex models |\n",
    "| **Logistic Regression** | - Simple and easy to implement<br> - Efficient for binary classification tasks<br> - Provides probabilities for outcomes | - Can struggle with complex relationships in data<br> - Not the best choice for non-linear problems |\n",
    "| **Random Forest** | - Handles non-linear data well<br> - Less prone to overfitting<br> - Good for classification and regression | - Can be slow on large datasets<br> - Model interpretability can be challenging |\n",
    "| **LSTM (Long Short-Term Memory)** | - Excellent for sequence data like text<br> - Can capture long-term dependencies<br> - Good for complex language modeling | - Computationally intensive<br> - Requires large training datasets<br> - Longer training times |\n",
    "| **BERT (Bidirectional Encoder Representations from Transformers)** | - State-of-the-art for NLP tasks<br> - Understands word context and nuances<br> - Highly accurate for various language tasks | - Requires significant computational resources<br> - Complex and requires fine-tuning<br> - Overkill for simpler tasks |\n",
    "\n",
    "\n",
    "**SVM, Naive Bayes, Logistic Regression, and Random Forest**: These are traditional machine learning models and are generally less complex and computationally intensive compared to LSTM and BERT. They can be effective for smaller datasets or less complex sentiment analysis tasks but might not capture the intricacies of language as effectively as LSTM or BERT.\n",
    "\n",
    "**LSTM and BERT**: These are advanced deep learning models that excel in understanding language context and complexities. They are more suitable for large datasets and complex NLP tasks, but their need for significant computational resources and longer training times can be a drawback, especially in resource-constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930dd94",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15eb1c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16917x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2126859 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279f17",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543826e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5569b75",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d6e27b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score: 0.8211861215498342\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and best score\n",
    "svm_best_parameters = grid_search.best_params_\n",
    "svm_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", svm_best_parameters)\n",
    "print(\"Best Score:\", svm_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d68b",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfdccf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8440323347598668\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_search.best_estimator_\n",
    "test_accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cfc9e",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420733cf",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "060857ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 309 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100]}, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Define the parameter grid\n",
    "# Naive Bayes usually has fewer hyperparameters to tune, but you can experiment with alpha\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100]  # Additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(nb_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0973a",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fd08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01}\n",
      "Best Score: 0.70265147099448\n"
     ]
    }
   ],
   "source": [
    "nb_best_parameters = grid_search.best_params_\n",
    "nb_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", nb_best_parameters)\n",
    "print(\"Best Score:\", nb_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387e5fb",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d2da47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7208749405611032\n"
     ]
    }
   ],
   "source": [
    "best_nb = grid_search.best_estimator_\n",
    "test_accuracy = best_nb.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7cae7",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b00dc",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d04a361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Algorithm to use in optimization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b9228",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "504f6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'solver': 'saga'}\n",
      "Best Score: 0.8310532759927739\n"
     ]
    }
   ],
   "source": [
    "lr_best_parameters = grid_search.best_params_\n",
    "lr_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", lr_best_parameters)\n",
    "print(\"Best Score:\", lr_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3faede",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9576bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8549690917736567\n"
     ]
    }
   ],
   "source": [
    "best_lr = grid_search.best_estimator_\n",
    "test_accuracy = best_lr.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16d183",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de2aab",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "832dc00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da475185",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff95b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Score: 0.7499685248653563\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and best score\n",
    "forest_best_parameters = grid_search.best_params_\n",
    "forest_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", forest_best_parameters)\n",
    "print(\"Best Score:\", forest_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06c386",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0643dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7689015691868759\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data (optional)\n",
    "best_rf = grid_search.best_estimator_\n",
    "test_accuracy = best_rf.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b16ee0",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb4615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of all the models\n",
    "best_estimators = {\n",
    "    'SVM': best_svm,\n",
    "    'Naive Bayes': best_nb,\n",
    "    'Logistic Regression': best_lr,\n",
    "    'Random Forest': best_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c277928",
   "metadata": {},
   "source": [
    "Dummy classifier as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53c365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Implement the Dummy Classifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "# Add the Dummy Classifier to your best estimators dictionary\n",
    "best_estimators['Dummy Classifier'] = dummy_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51106e",
   "metadata": {},
   "source": [
    "#### Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "debcbd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.8440323347598668, Precision: 0.8385714980166168, Recall: 0.8440323347598668, F1 Score: 0.835704406363735\n",
      "Naive Bayes - Accuracy: 0.7208749405611032, Precision: 0.7149331227896696, Recall: 0.7208749405611032, F1 Score: 0.6783429621715981\n",
      "Logistic Regression - Accuracy: 0.8549690917736567, Precision: 0.8496069060849031, Recall: 0.8549690917736567, F1 Score: 0.8503726335406443\n",
      "Random Forest - Accuracy: 0.7689015691868759, Precision: 0.806421920536521, Recall: 0.7689015691868759, F1 Score: 0.7248527080214562\n",
      "Dummy Classifier - Accuracy: 0.6814075130765573, Precision: 0.4643161988771786, Recall: 0.6814075130765573, F1 Score: 0.5522946641621643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all models\n",
    "predictions = {model: estimator.predict(X_test) for model, estimator in best_estimators.items()}\n",
    "\n",
    "# Initialize a dictionary to hold the metrics\n",
    "metrics_summary = {}\n",
    "\n",
    "# Calculate metrics for all models\n",
    "for model, model_predictions in predictions.items():\n",
    "    accuracy = accuracy_score(y_test, model_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, model_predictions, average='weighted')\n",
    "    metrics_summary[model] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Display the metrics for each model including the Dummy Classifier\n",
    "for model, metrics in metrics_summary.items():\n",
    "    print(f\"{model} - Accuracy: {metrics['Accuracy']}, Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b5177",
   "metadata": {},
   "source": [
    "Metrict table to be copy pasted into overleaf to save time <3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ae2ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & Accuracy & Precision & Recall & F1 Score \\\\\n",
      "\\midrule\n",
      "SVM & 0.84 & 0.84 & 0.84 & 0.84 \\\\\n",
      "Naive Bayes & 0.72 & 0.71 & 0.72 & 0.68 \\\\\n",
      "Logistic Regression & 0.85 & 0.85 & 0.85 & 0.85 \\\\\n",
      "Random Forest & 0.77 & 0.81 & 0.77 & 0.72 \\\\\n",
      "Dummy Classifier & 0.68 & 0.46 & 0.68 & 0.55 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert metrics_summary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_summary).transpose()\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df.to_latex(float_format=\"%.2f\", header=True, index=True)\n",
    "\n",
    "# Printing the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40779bb2",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "These results provide a comparison of the performance of various machine learning models (SVM, Naive Bayes, Logistic Regression, Random Forest) and a baseline Dummy Classifier on your dataset, based on different metrics. Let's break down what each metric means and what the results indicate:\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "*Definition*: The proportion of correct predictions among the total number of cases evaluated.\n",
    "*Results*: Logistic Regression performed the best with an accuracy of about 85.50%, followed closely by SVM. The Dummy Classifier, as expected, has the lowest accuracy.\n",
    "\n",
    "**Precision**\n",
    "\n",
    "*Definition*: The ratio of correctly predicted positive observations to the total predicted positives. High precision relates to a low false positive rate.\n",
    "*Results*: Logistic Regression again leads in precision, suggesting it's better at minimizing false positives. Naive Bayes has the lowest precision among the advanced models, indicating more false positives.\n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "\n",
    "*Definition*: The ratio of correctly predicted positive observations to all observations in the actual class. It shows how many of the actual positives were captured by the model.\n",
    "*Results*: Similar to accuracy, Logistic Regression and SVM have high recall, meaning they are good at capturing actual positives. The Dummy Classifier has a high recall too, but this is misleading since it always predicts the most frequent class, ignoring the actual class distribution.\n",
    "\n",
    "**F1 Score**\n",
    "\n",
    "*Definition*: The weighted average of Precision and Recall. It takes both false positives and false negatives into account. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "*Results*: Logistic Regression has the highest F1 score, indicating a good balance between precision and recall. Naive Bayes has a significantly lower F1 score, suggesting it doesn't balance precision and recall as well as the other models.\n",
    "\n",
    "**Overall Analysis**\n",
    "\n",
    "Logistic Regression appears to be the most effective model for your dataset, performing well across all metrics. It seems to offer a good balance between identifying relevant instances and minimizing incorrect classifications.\n",
    "SVM also performs well, especially in terms of recall and accuracy, making it a strong contender.\n",
    "Naive Bayes, while faster and simpler, doesn't perform as well in this context, particularly in terms of precision and F1 score.\n",
    "Random Forest shows moderate performance, but it's outperformed by both Logistic Regression and SVM.\n",
    "Dummy Classifier serves as a baseline, and as expected, it has the lowest performance. However, its results are important to understand the minimum threshold any sophisticated model should surpass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ebab9",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee066545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0a8b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mislabeling percentages for SVM:\n",
      "Label negative: 33.02% mislabeled\n",
      "Label neutral: 83.78% mislabeled\n",
      "Label positive: 6.14% mislabeled\n",
      "\n",
      "Mislabeling percentages for Naive Bayes:\n",
      "Label negative: 74.72% mislabeled\n",
      "Label neutral: 64.86% mislabeled\n",
      "Label positive: 6.28% mislabeled\n",
      "\n",
      "Mislabeling percentages for Logistic Regression:\n",
      "Label negative: 25.91% mislabeled\n",
      "Label neutral: 78.38% mislabeled\n",
      "Label positive: 7.82% mislabeled\n",
      "\n",
      "Mislabeling percentages for Random Forest:\n",
      "Label negative: 71.09% mislabeled\n",
      "Label neutral: 56.76% mislabeled\n",
      "Label positive: 1.05% mislabeled\n",
      "\n",
      "Mislabeling percentages for Dummy Classifier:\n",
      "Label negative: 100.00% mislabeled\n",
      "Label neutral: 100.00% mislabeled\n",
      "Label positive: 0.00% mislabeled\n"
     ]
    }
   ],
   "source": [
    "# Mapping for your labels\n",
    "label_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Generate the confusion matrix for the current model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mislabeling percentage for each label\n",
    "    mislabeling_percentages = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    mislabeling_percentages = mislabeling_percentages / np.sum(cm, axis=1) * 100\n",
    "\n",
    "    print(f\"\\nMislabeling percentages for {model_name}:\")\n",
    "    for label_idx, mislabel_pct in enumerate(mislabeling_percentages):\n",
    "        label_name = label_mapping.get(label_idx, f\"Label {label_idx}\")\n",
    "        print(f\"Label {label_name}: {mislabel_pct:.2f}% mislabeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78e9a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.12992200875024%\n",
      "Precentage of positive labels: 67.26269735590641%\n",
      "Precentage of neutral labels: 1.6073806353433517%\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df[df['sentiment']=='Negative'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df[df['sentiment']=='Positive'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of neutral labels: {len(df[df['sentiment']=='Neutral'])/len(df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c28d1",
   "metadata": {},
   "source": [
    "The high mislabeling percentages for certain labels alongside overall high accuracy for models like Logistic Regression (LR) and Support Vector Machine (SVM) can be explained by a few factors, particularly the distribution of classes (labels) in your dataset. \n",
    "\n",
    "Let's focus on our two best performars, svm and lr. The mislabelling percetages concern mostly the Neutral class, which respresents less than 2% of the whole dataset.  In an imbalanced dataset, the minority classes (like 'neutral' -1.6%- or 'negative' -31%) have fewer instances, so even a high percentage of mislabeling in these classes might not significantly impact the overall accuracy if the model performs exceedingly well on the majority class.\n",
    "\n",
    "How could we fix that? Idealy we would have used oversamling, undersampling or generation (smote) techniques but I realized that very late, which hightlights the importance of exploring your dataset before actually going forward with your models 🙃."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e89940",
   "metadata": {},
   "source": [
    "#### Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02705f85",
   "metadata": {},
   "source": [
    "We are conducting further statistical testing between our two top persorming models.\n",
    "\n",
    "First we are conducting a Shapiro-Wilk test with H0: \"Differences between the two models' scores seem to be normally distributed (fail to reject H0)\". If we failt to reject H0 then we can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92c27391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences seem to be normally distributed (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Obtain cross-validation scores for each model\n",
    "scores_lr = cross_val_score(best_lr, X_tfidf, y, cv=5)\n",
    "scores_svm = cross_val_score(best_svm, X_tfidf, y, cv=5)\n",
    "\n",
    "# Calculate differences between sets of scores\n",
    "score_diffs = scores_lr - scores_svm\n",
    "\n",
    "# Shapiro-Wilk Test for Normality\n",
    "stat, p = shapiro(score_diffs)\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Differences seem to be normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('Differences do not appear to be normally distributed (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2409a7",
   "metadata": {},
   "source": [
    "Interpreting the Shapiro-Wilk test result \"Differences seem to be normally distributed (fail to reject H0)\" in the context of comparing your best_lr (Logistic Regression) and best_svm (Support Vector Machine) models indicates that the differences in their cross-validation scores do not significantly deviate from a normal distribution. This means you can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d246241",
   "metadata": {},
   "source": [
    "Now let's perform a paired t-test to determine if the differences in performance between the models are statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd85f4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test between Logistic Regression and SVM:\n",
      "T-statistic: 6.581093552269545, P-value: 0.002759946835786729\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_rel(scores_lr, scores_svm)\n",
    "\n",
    "print(f\"Paired t-test between Logistic Regression and SVM:\\nT-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00383e44",
   "metadata": {},
   "source": [
    "**Statistical Significance**: Given that the p-value is less than 0.05, you can reject the null hypothesis. This means there is a statistically significant difference in the performance of the Logistic Regression and SVM models on your dataset.\n",
    "\n",
    "**Model Performance**: The positive t-statistic value indicates that the mean cross-validation score of the Logistic Regression model is higher than that of the SVM model. This suggests that Logistic Regression performs better than SVM on your dataset, with this difference being statistically significant.\n",
    "\n",
    "------------------------\n",
    "Corresponding latex table:\n",
    "\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Model Comparison} & \\textbf{T-Statistic} & \\textbf{P-Value} \\\\ \\hline\n",
    "Logistic Regression vs SVM & 6.581 & 0.00276 \\\\ \\hline\n",
    "% Add more rows for other model comparisons if you have them\n",
    "% Example: Model A vs Model B & T-Statistic Value & P-Value \\\\\n",
    "\\end{tabular}\n",
    "\\caption{Paired T-Test Results Between Models}\n",
    "\\label{tab:my_label}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e68764",
   "metadata": {},
   "source": [
    "In summary, this result indicates that Logistic Regression is not only performing better than SVM on average, but that this better performance is statistically significant and not likely due to random chance or variability in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
