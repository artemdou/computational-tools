{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f894ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92acf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2405cd",
   "metadata": {},
   "source": [
    "### Lyric preprocessing & Sentiment annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc2234",
   "metadata": {},
   "source": [
    "Read data from local csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a16cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"songs_with_lyrics_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70926a81",
   "metadata": {},
   "source": [
    "Clean lyrics from the following:\n",
    "* \\n\n",
    "* [something]\n",
    "\n",
    "Also explored invalid urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da130194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics):\n",
    "    # Remove text within brackets\n",
    "    cleaned_lyrics = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \"\", lyrics)\n",
    "\n",
    "    # Capitalize the first letter of each line\n",
    "    cleaned_lyrics = cleaned_lyrics.replace('\\n', \" \")\n",
    "    cleaned_lyrics = cleaned_lyrics.strip(\" \")\n",
    "\n",
    "    return cleaned_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8d39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to your DataFrame\n",
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c57ec1",
   "metadata": {},
   "source": [
    "After data exploration, we realize that some extra and more custom cleaning is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2da8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this url is not the url of a song\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Scopey-almost-every-album-ive-listened-to-lyrics'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Hossein-amini-drive-annotated'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Genius-valentines-day-playlists-lyrics'].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c2fa3",
   "metadata": {},
   "source": [
    "Label songs based on their lyric sentiments.\n",
    "\n",
    "Used textblob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47ba208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sentiment analysis using TextBlob\n",
    "def get_sentiment(lyrics):\n",
    "    try:\n",
    "        blob = TextBlob(lyrics)\n",
    "        # TextBlob returns polarity and subjectivity, you can use just polarity for a simple positive/negative/neutral sentiment\n",
    "        polarity = blob.sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            return \"Positive\"\n",
    "        elif polarity < 0:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing lyrics: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_lyrics(lyric):\n",
    "    cleaned_lyrics = re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6303e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 50.8 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['sentiment'] = df['lyrics'].apply(lambda lyrics: get_sentiment(lyrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aab5e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>playlist</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10501</th>\n",
       "      <td>0TujvmfSqowyT2OiimLaBY</td>\n",
       "      <td>welcome to my world</td>\n",
       "      <td>6bmlMHgSheBauioMgKv2tn</td>\n",
       "      <td>Powfu</td>\n",
       "      <td>49</td>\n",
       "      <td>['37i9dQZF1DXdWMJMjqz9bm', '37i9dQZF1DX6xZZEgC...</td>\n",
       "      <td>https://genius.com/Powfu-ouse-and-snw-welcome-...</td>\n",
       "      <td>Yo, Ouse, this is crazy   They don't know what...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>6ORqU0bHbVCRjXm9AjyHyZ</td>\n",
       "      <td>Good Riddance (Time of Your Life)</td>\n",
       "      <td>7oPftvlwr6VrsViSDV7fJY</td>\n",
       "      <td>Green Day</td>\n",
       "      <td>83</td>\n",
       "      <td>['37i9dQZF1DX15JKV0q7shD', '37i9dQZF1DX9vEn8vB...</td>\n",
       "      <td>https://genius.com/Green-day-good-riddance-tim...</td>\n",
       "      <td>Fuck...  Another turnin' point, a fork stuck i...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>4YwR2G26Pp5jNUX3gN3EIP</td>\n",
       "      <td>When Love And Hate Collide</td>\n",
       "      <td>6H1RjVyNruCmrBEWRbD0VZ</td>\n",
       "      <td>Def Leppard</td>\n",
       "      <td>63</td>\n",
       "      <td>['4w6q4K9tQTlTNUWkLVJG3m', '1yzrrSn0LYzx3vWTOD...</td>\n",
       "      <td>https://genius.com/Def-leppard-when-love-and-h...</td>\n",
       "      <td>You could have a change of heart, if you would...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>18uwL0vNUanqZH0ro2QcOP</td>\n",
       "      <td>comethru</td>\n",
       "      <td>3gIRvgZssIb9aiirIg0nI3</td>\n",
       "      <td>Jeremy Zucker</td>\n",
       "      <td>79</td>\n",
       "      <td>['4NHM3HqdFHRyQifPo9GZAB', '3c0Nv5CY6TIaRszlTZ...</td>\n",
       "      <td>https://genius.com/Jeremy-zucker-comethru-lyrics</td>\n",
       "      <td>I might lose my mind Waking when the sun's dow...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>45zvStEMsXp8z45OQRhWFJ</td>\n",
       "      <td>American Idiot</td>\n",
       "      <td>7oPftvlwr6VrsViSDV7fJY</td>\n",
       "      <td>Green Day</td>\n",
       "      <td>64</td>\n",
       "      <td>['4KDNMkiTFX87uz4rlI68v0', '37i9dQZF1DX3oM43Ct...</td>\n",
       "      <td>https://genius.com/Green-day-american-idiot-ly...</td>\n",
       "      <td>Don't wanna be an American idiot Don't want a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>5URJEznfi3XiVHQCyC3sII</td>\n",
       "      <td>The Darkest Nights</td>\n",
       "      <td>2vd2HnNh4pdYa9gDVHFjEu</td>\n",
       "      <td>As I Lay Dying</td>\n",
       "      <td>50</td>\n",
       "      <td>['2c9ceMk120EbDuvbxVTz0K']</td>\n",
       "      <td>https://genius.com/As-i-lay-dying-the-darkest-...</td>\n",
       "      <td>For so, long I, have felt alone Content, to li...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>00hLXIe28fT2kqQNYE7uNc</td>\n",
       "      <td>Nothing Like It</td>\n",
       "      <td>0tCtGc5vt29zFZp6KXzN50</td>\n",
       "      <td>Beanie Sigel</td>\n",
       "      <td>34</td>\n",
       "      <td>['5l2hgSzfMqBRMumwZZjlE7']</td>\n",
       "      <td>https://genius.com/Beanie-sigel-nothing-like-i...</td>\n",
       "      <td>I'm just I'm just a picture A picture in a fra...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>2XEl9DfBj88c8p2bdfx1qu</td>\n",
       "      <td>One Hell Of An Amen</td>\n",
       "      <td>5q8HGNo0BjLWaTAhRtbwxa</td>\n",
       "      <td>Brantley Gilbert</td>\n",
       "      <td>55</td>\n",
       "      <td>['0wqUVPa19eClnNClEMQQoY']</td>\n",
       "      <td>https://genius.com/Brantley-gilbert-one-hell-o...</td>\n",
       "      <td>Preacher said he died too young Over there tot...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>799XxzSlWNYkuWJxUbuGnF</td>\n",
       "      <td>Master of Puppets</td>\n",
       "      <td>2ye2Wgw4gimLv2eAKyk1NB</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>60</td>\n",
       "      <td>['7L8L3zGOZ8UzMiO84h4rau']</td>\n",
       "      <td>https://genius.com/Metallica-master-of-puppets...</td>\n",
       "      <td>End of passion play, crumbling away I'm your s...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>7F9TZ2RT8rdVyzLFmfagiR</td>\n",
       "      <td>Little Runaway</td>\n",
       "      <td>22wbnEMDvgVIAGdFeek6ET</td>\n",
       "      <td>Benson Boone</td>\n",
       "      <td>61</td>\n",
       "      <td>['37i9dQZF1DX7qK8ma5wgG1']</td>\n",
       "      <td>https://genius.com/Benson-boone-little-runaway...</td>\n",
       "      <td>Little runaway, the world's never easy You're ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      song_id                          song_name  \\\n",
       "10501  0TujvmfSqowyT2OiimLaBY                welcome to my world   \n",
       "3057   6ORqU0bHbVCRjXm9AjyHyZ  Good Riddance (Time of Your Life)   \n",
       "9754   4YwR2G26Pp5jNUX3gN3EIP         When Love And Hate Collide   \n",
       "10339  18uwL0vNUanqZH0ro2QcOP                           comethru   \n",
       "407    45zvStEMsXp8z45OQRhWFJ                     American Idiot   \n",
       "8244   5URJEznfi3XiVHQCyC3sII                 The Darkest Nights   \n",
       "5871   00hLXIe28fT2kqQNYE7uNc                    Nothing Like It   \n",
       "6039   2XEl9DfBj88c8p2bdfx1qu                One Hell Of An Amen   \n",
       "5156   799XxzSlWNYkuWJxUbuGnF                  Master of Puppets   \n",
       "4762   7F9TZ2RT8rdVyzLFmfagiR                     Little Runaway   \n",
       "\n",
       "                    artist_id       artist_name  popularity  \\\n",
       "10501  6bmlMHgSheBauioMgKv2tn             Powfu          49   \n",
       "3057   7oPftvlwr6VrsViSDV7fJY         Green Day          83   \n",
       "9754   6H1RjVyNruCmrBEWRbD0VZ       Def Leppard          63   \n",
       "10339  3gIRvgZssIb9aiirIg0nI3     Jeremy Zucker          79   \n",
       "407    7oPftvlwr6VrsViSDV7fJY         Green Day          64   \n",
       "8244   2vd2HnNh4pdYa9gDVHFjEu    As I Lay Dying          50   \n",
       "5871   0tCtGc5vt29zFZp6KXzN50      Beanie Sigel          34   \n",
       "6039   5q8HGNo0BjLWaTAhRtbwxa  Brantley Gilbert          55   \n",
       "5156   2ye2Wgw4gimLv2eAKyk1NB         Metallica          60   \n",
       "4762   22wbnEMDvgVIAGdFeek6ET      Benson Boone          61   \n",
       "\n",
       "                                                playlist  \\\n",
       "10501  ['37i9dQZF1DXdWMJMjqz9bm', '37i9dQZF1DX6xZZEgC...   \n",
       "3057   ['37i9dQZF1DX15JKV0q7shD', '37i9dQZF1DX9vEn8vB...   \n",
       "9754   ['4w6q4K9tQTlTNUWkLVJG3m', '1yzrrSn0LYzx3vWTOD...   \n",
       "10339  ['4NHM3HqdFHRyQifPo9GZAB', '3c0Nv5CY6TIaRszlTZ...   \n",
       "407    ['4KDNMkiTFX87uz4rlI68v0', '37i9dQZF1DX3oM43Ct...   \n",
       "8244                          ['2c9ceMk120EbDuvbxVTz0K']   \n",
       "5871                          ['5l2hgSzfMqBRMumwZZjlE7']   \n",
       "6039                          ['0wqUVPa19eClnNClEMQQoY']   \n",
       "5156                          ['7L8L3zGOZ8UzMiO84h4rau']   \n",
       "4762                          ['37i9dQZF1DX7qK8ma5wgG1']   \n",
       "\n",
       "                                              lyrics_url  \\\n",
       "10501  https://genius.com/Powfu-ouse-and-snw-welcome-...   \n",
       "3057   https://genius.com/Green-day-good-riddance-tim...   \n",
       "9754   https://genius.com/Def-leppard-when-love-and-h...   \n",
       "10339   https://genius.com/Jeremy-zucker-comethru-lyrics   \n",
       "407    https://genius.com/Green-day-american-idiot-ly...   \n",
       "8244   https://genius.com/As-i-lay-dying-the-darkest-...   \n",
       "5871   https://genius.com/Beanie-sigel-nothing-like-i...   \n",
       "6039   https://genius.com/Brantley-gilbert-one-hell-o...   \n",
       "5156   https://genius.com/Metallica-master-of-puppets...   \n",
       "4762   https://genius.com/Benson-boone-little-runaway...   \n",
       "\n",
       "                                                  lyrics language sentiment  \n",
       "10501  Yo, Ouse, this is crazy   They don't know what...       en  Positive  \n",
       "3057   Fuck...  Another turnin' point, a fork stuck i...       en  Positive  \n",
       "9754   You could have a change of heart, if you would...       en  Negative  \n",
       "10339  I might lose my mind Waking when the sun's dow...       en  Positive  \n",
       "407    Don't wanna be an American idiot Don't want a ...       en  Positive  \n",
       "8244   For so, long I, have felt alone Content, to li...       en  Negative  \n",
       "5871   I'm just I'm just a picture A picture in a fra...       en  Positive  \n",
       "6039   Preacher said he died too young Over there tot...       en  Positive  \n",
       "5156   End of passion play, crumbling away I'm your s...       en  Positive  \n",
       "4762   Little runaway, the world's never easy You're ...       en  Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c1d50",
   "metadata": {},
   "source": [
    "#### Lyric descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2beec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric descriptives\n",
      "--------------------------\n",
      "Number of songs: 10514\n",
      "Average number of characters in a song's lyrics: 1895.2707818147233\n",
      "Average number of words in a song's lyrics: 376.53671295415637\n"
     ]
    }
   ],
   "source": [
    "rows = len(df)\n",
    "average_length = df['lyrics'].str.len().mean()\n",
    "average_words = df['lyrics'].apply(lambda x: len(x.split())).mean()\n",
    "print(\"Lyric descriptives\")\n",
    "print(\"--------------------------\")\n",
    "print(f\"Number of songs: {rows}\")\n",
    "print(f\"Average number of characters in a song's lyrics: {average_length}\")\n",
    "print(f\"Average number of words in a song's lyrics: {average_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e48745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.12992200875024%\n",
      "Precentage of positive labels: 67.26269735590641%\n",
      "Precentage of neutral labels: 1.6073806353433517%\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df[df['sentiment']=='Negative'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df[df['sentiment']=='Positive'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of neutral labels: {len(df[df['sentiment']=='Neutral'])/len(df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2bf1d",
   "metadata": {},
   "source": [
    "### Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976a7bc",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Preprocessing with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['lyrics'])\n",
    "y = df['encoded_sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed702783",
   "metadata": {},
   "source": [
    "**Algorithm selectio**\n",
    "\n",
    "We keep in mind the computational resources needed for the algorithms. Maybe we don't end up with the stringest model, but we aim for the most feasibly reliable one.\n",
    "\n",
    "| Algorithm | Pros | Cons |\n",
    "|-----------|------|------|\n",
    "| **SVM (Support Vector Machine)** | - Effective in high-dimensional spaces<br> - Works well with a clear margin of separation<br> - Less prone to overfitting | - Not suitable for very large datasets<br> - Requires feature scaling<br> - Can be less effective with overlapping classes |\n",
    "| **Naive Bayes** | - Fast and efficient<br> - Works well with high-dimensional data<br> - Effective for text classification | - Based on the assumption of feature independence<br> - Can be outperformed by more complex models |\n",
    "| **Logistic Regression** | - Simple and easy to implement<br> - Efficient for binary classification tasks<br> - Provides probabilities for outcomes | - Can struggle with complex relationships in data<br> - Not the best choice for non-linear problems |\n",
    "| **Random Forest** | - Handles non-linear data well<br> - Less prone to overfitting<br> - Good for classification and regression | - Can be slow on large datasets<br> - Model interpretability can be challenging |\n",
    "| **LSTM (Long Short-Term Memory)** | - Excellent for sequence data like text<br> - Can capture long-term dependencies<br> - Good for complex language modeling | - Computationally intensive<br> - Requires large training datasets<br> - Longer training times |\n",
    "| **BERT (Bidirectional Encoder Representations from Transformers)** | - State-of-the-art for NLP tasks<br> - Understands word context and nuances<br> - Highly accurate for various language tasks | - Requires significant computational resources<br> - Complex and requires fine-tuning<br> - Overkill for simpler tasks |\n",
    "\n",
    "\n",
    "**SVM, Naive Bayes, Logistic Regression, and Random Forest**: These are traditional machine learning models and are generally less complex and computationally intensive compared to LSTM and BERT. They can be effective for smaller datasets or less complex sentiment analysis tasks but might not capture the intricacies of language as effectively as LSTM or BERT.\n",
    "\n",
    "**LSTM and BERT**: These are advanced deep learning models that excel in understanding language context and complexities. They are more suitable for large datasets and complex NLP tasks, but their need for significant computational resources and longer training times can be a drawback, especially in resource-constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930dd94",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279f17",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543826e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5569b75",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d6e27b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score: 0.8211861215498342\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and best score\n",
    "svm_best_parameters = grid_search.best_params_\n",
    "svm_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", svm_best_parameters)\n",
    "print(\"Best Score:\", svm_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d68b",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfdccf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8440323347598668\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_search.best_estimator_\n",
    "test_accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cfc9e",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420733cf",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "060857ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 309 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100]}, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Define the parameter grid\n",
    "# Naive Bayes usually has fewer hyperparameters to tune, but you can experiment with alpha\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100]  # Additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(nb_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0973a",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fd08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01}\n",
      "Best Score: 0.70265147099448\n"
     ]
    }
   ],
   "source": [
    "nb_best_parameters = grid_search.best_params_\n",
    "nb_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", nb_best_parameters)\n",
    "print(\"Best Score:\", nb_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387e5fb",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d2da47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7208749405611032\n"
     ]
    }
   ],
   "source": [
    "best_nb = grid_search.best_estimator_\n",
    "test_accuracy = best_nb.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7cae7",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b00dc",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d04a361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Algorithm to use in optimization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b9228",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "504f6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'solver': 'saga'}\n",
      "Best Score: 0.8310532759927739\n"
     ]
    }
   ],
   "source": [
    "lr_best_parameters = grid_search.best_params_\n",
    "lr_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", lr_best_parameters)\n",
    "print(\"Best Score:\", lr_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3faede",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9576bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8549690917736567\n"
     ]
    }
   ],
   "source": [
    "best_lr = grid_search.best_estimator_\n",
    "test_accuracy = best_lr.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16d183",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de2aab",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "832dc00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30, None],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da475185",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff95b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Score: 0.7499685248653563\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and best score\n",
    "forest_best_parameters = grid_search.best_params_\n",
    "forest_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", forest_best_parameters)\n",
    "print(\"Best Score:\", forest_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06c386",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0643dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7689015691868759\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data (optional)\n",
    "best_rf = grid_search.best_estimator_\n",
    "test_accuracy = best_rf.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b16ee0",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb4615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of all the models\n",
    "best_estimators = {\n",
    "    'SVM': best_svm,\n",
    "    'Naive Bayes': best_nb,\n",
    "    'Logistic Regression': best_lr,\n",
    "    'Random Forest': best_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c277928",
   "metadata": {},
   "source": [
    "Dummy classifier as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53c365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Implement the Dummy Classifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "# Add the Dummy Classifier to your best estimators dictionary\n",
    "best_estimators['Dummy Classifier'] = dummy_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51106e",
   "metadata": {},
   "source": [
    "#### Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "debcbd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.8440323347598668, Precision: 0.8385714980166168, Recall: 0.8440323347598668, F1 Score: 0.835704406363735\n",
      "Naive Bayes - Accuracy: 0.7208749405611032, Precision: 0.7149331227896696, Recall: 0.7208749405611032, F1 Score: 0.6783429621715981\n",
      "Logistic Regression - Accuracy: 0.8549690917736567, Precision: 0.8496069060849031, Recall: 0.8549690917736567, F1 Score: 0.8503726335406443\n",
      "Random Forest - Accuracy: 0.7689015691868759, Precision: 0.806421920536521, Recall: 0.7689015691868759, F1 Score: 0.7248527080214562\n",
      "Dummy Classifier - Accuracy: 0.6814075130765573, Precision: 0.4643161988771786, Recall: 0.6814075130765573, F1 Score: 0.5522946641621643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all models\n",
    "predictions = {model: estimator.predict(X_test) for model, estimator in best_estimators.items()}\n",
    "\n",
    "# Initialize a dictionary to hold the metrics\n",
    "metrics_summary = {}\n",
    "\n",
    "# Calculate metrics for all models\n",
    "for model, model_predictions in predictions.items():\n",
    "    accuracy = accuracy_score(y_test, model_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, model_predictions, average='weighted')\n",
    "    metrics_summary[model] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Display the metrics for each model including the Dummy Classifier\n",
    "for model, metrics in metrics_summary.items():\n",
    "    print(f\"{model} - Accuracy: {metrics['Accuracy']}, Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b5177",
   "metadata": {},
   "source": [
    "Metrict table to be copy pasted into overleaf to save time <3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ae2ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & Accuracy & Precision & Recall & F1 Score \\\\\n",
      "\\midrule\n",
      "SVM & 0.84 & 0.84 & 0.84 & 0.84 \\\\\n",
      "Naive Bayes & 0.72 & 0.71 & 0.72 & 0.68 \\\\\n",
      "Logistic Regression & 0.85 & 0.85 & 0.85 & 0.85 \\\\\n",
      "Random Forest & 0.77 & 0.81 & 0.77 & 0.72 \\\\\n",
      "Dummy Classifier & 0.68 & 0.46 & 0.68 & 0.55 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert metrics_summary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_summary).transpose()\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df.to_latex(float_format=\"%.2f\", header=True, index=True)\n",
    "\n",
    "# Printing the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40779bb2",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "These results provide a comparison of the performance of various machine learning models (SVM, Naive Bayes, Logistic Regression, Random Forest) and a baseline Dummy Classifier on your dataset, based on different metrics. Let's break down what each metric means and what the results indicate:\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "*Definition*: The proportion of correct predictions among the total number of cases evaluated.\n",
    "*Results*: Logistic Regression performed the best with an accuracy of about 85.50%, followed closely by SVM. The Dummy Classifier, as expected, has the lowest accuracy.\n",
    "\n",
    "**Precision**\n",
    "\n",
    "*Definition*: The ratio of correctly predicted positive observations to the total predicted positives. High precision relates to a low false positive rate.\n",
    "*Results*: Logistic Regression again leads in precision, suggesting it's better at minimizing false positives. Naive Bayes has the lowest precision among the advanced models, indicating more false positives.\n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "\n",
    "*Definition*: The ratio of correctly predicted positive observations to all observations in the actual class. It shows how many of the actual positives were captured by the model.\n",
    "*Results*: Similar to accuracy, Logistic Regression and SVM have high recall, meaning they are good at capturing actual positives. The Dummy Classifier has a high recall too, but this is misleading since it always predicts the most frequent class, ignoring the actual class distribution.\n",
    "\n",
    "**F1 Score**\n",
    "\n",
    "*Definition*: The weighted average of Precision and Recall. It takes both false positives and false negatives into account. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "*Results*: Logistic Regression has the highest F1 score, indicating a good balance between precision and recall. Naive Bayes has a significantly lower F1 score, suggesting it doesn't balance precision and recall as well as the other models.\n",
    "\n",
    "**Overall Analysis**\n",
    "\n",
    "Logistic Regression appears to be the most effective model for your dataset, performing well across all metrics. It seems to offer a good balance between identifying relevant instances and minimizing incorrect classifications.\n",
    "SVM also performs well, especially in terms of recall and accuracy, making it a strong contender.\n",
    "Naive Bayes, while faster and simpler, doesn't perform as well in this context, particularly in terms of precision and F1 score.\n",
    "Random Forest shows moderate performance, but it's outperformed by both Logistic Regression and SVM.\n",
    "Dummy Classifier serves as a baseline, and as expected, it has the lowest performance. However, its results are important to understand the minimum threshold any sophisticated model should surpass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ebab9",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee066545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0a8b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mislabeling percentages for SVM:\n",
      "Label negative: 33.02% mislabeled\n",
      "Label neutral: 83.78% mislabeled\n",
      "Label positive: 6.14% mislabeled\n",
      "\n",
      "Mislabeling percentages for Naive Bayes:\n",
      "Label negative: 74.72% mislabeled\n",
      "Label neutral: 64.86% mislabeled\n",
      "Label positive: 6.28% mislabeled\n",
      "\n",
      "Mislabeling percentages for Logistic Regression:\n",
      "Label negative: 25.91% mislabeled\n",
      "Label neutral: 78.38% mislabeled\n",
      "Label positive: 7.82% mislabeled\n",
      "\n",
      "Mislabeling percentages for Random Forest:\n",
      "Label negative: 71.09% mislabeled\n",
      "Label neutral: 56.76% mislabeled\n",
      "Label positive: 1.05% mislabeled\n",
      "\n",
      "Mislabeling percentages for Dummy Classifier:\n",
      "Label negative: 100.00% mislabeled\n",
      "Label neutral: 100.00% mislabeled\n",
      "Label positive: 0.00% mislabeled\n"
     ]
    }
   ],
   "source": [
    "# Mapping for your labels\n",
    "label_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Generate the confusion matrix for the current model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mislabeling percentage for each label\n",
    "    mislabeling_percentages = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    mislabeling_percentages = mislabeling_percentages / np.sum(cm, axis=1) * 100\n",
    "\n",
    "    print(f\"\\nMislabeling percentages for {model_name}:\")\n",
    "    for label_idx, mislabel_pct in enumerate(mislabeling_percentages):\n",
    "        label_name = label_mapping.get(label_idx, f\"Label {label_idx}\")\n",
    "        print(f\"Label {label_name}: {mislabel_pct:.2f}% mislabeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78e9a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.12992200875024%\n",
      "Precentage of positive labels: 67.26269735590641%\n",
      "Precentage of neutral labels: 1.6073806353433517%\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df[df['sentiment']=='Negative'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df[df['sentiment']=='Positive'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of neutral labels: {len(df[df['sentiment']=='Neutral'])/len(df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c28d1",
   "metadata": {},
   "source": [
    "The high mislabeling percentages for certain labels alongside overall high accuracy for models like Logistic Regression (LR) and Support Vector Machine (SVM) can be explained by a few factors, particularly the distribution of classes (labels) in your dataset. \n",
    "\n",
    "Let's focus on our two best performars, svm and lr. The mislabelling percetages concern mostly the Neutral class, which respresents less than 2% of the whole dataset.  In an imbalanced dataset, the minority classes (like 'neutral' -1.6%- or 'negative' -31%) have fewer instances, so even a high percentage of mislabeling in these classes might not significantly impact the overall accuracy if the model performs exceedingly well on the majority class.\n",
    "\n",
    "How could we fix that? Idealy we would use oversampling or undersampling techniques. Oversampling is too computationally intensive so unfortunatelly we will not implement it. Undersamping on the other hand is tested at the end of this analysis by exluding the extreme minority label (neutral) and undersampling from the majority label (positives) to match the negative one. \n",
    "\n",
    "We are now continuing with the imbalanced analysis in order to have something to compare tot hte balanced one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e89940",
   "metadata": {},
   "source": [
    "#### Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02705f85",
   "metadata": {},
   "source": [
    "We are conducting further statistical testing between our two top persorming models.\n",
    "\n",
    "First we are conducting a Shapiro-Wilk test with H0: \"Differences between the two models' scores seem to be normally distributed (fail to reject H0)\". If we failt to reject H0 then we can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92c27391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences seem to be normally distributed (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Obtain cross-validation scores for each model\n",
    "scores_lr = cross_val_score(best_lr, X_tfidf, y, cv=5)\n",
    "scores_svm = cross_val_score(best_svm, X_tfidf, y, cv=5)\n",
    "\n",
    "# Calculate differences between sets of scores\n",
    "score_diffs = scores_lr - scores_svm\n",
    "\n",
    "# Shapiro-Wilk Test for Normality\n",
    "stat, p = shapiro(score_diffs)\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Differences seem to be normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('Differences do not appear to be normally distributed (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2409a7",
   "metadata": {},
   "source": [
    "Interpreting the Shapiro-Wilk test result \"Differences seem to be normally distributed (fail to reject H0)\" in the context of comparing your best_lr (Logistic Regression) and best_svm (Support Vector Machine) models indicates that the differences in their cross-validation scores do not significantly deviate from a normal distribution. This means you can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d246241",
   "metadata": {},
   "source": [
    "Now let's perform a paired t-test to determine if the differences in performance between the models are statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd85f4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test between Logistic Regression and SVM:\n",
      "T-statistic: 6.581093552269545, P-value: 0.002759946835786729\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_rel(scores_lr, scores_svm)\n",
    "\n",
    "print(f\"Paired t-test between Logistic Regression and SVM:\\nT-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00383e44",
   "metadata": {},
   "source": [
    "**Statistical Significance**: Given that the p-value is less than 0.05, you can reject the null hypothesis. This means there is a statistically significant difference in the performance of the Logistic Regression and SVM models on your dataset.\n",
    "\n",
    "**Model Performance**: The positive t-statistic value indicates that the mean cross-validation score of the Logistic Regression model is higher than that of the SVM model. This suggests that Logistic Regression performs better than SVM on your dataset, with this difference being statistically significant.\n",
    "\n",
    "------------------------\n",
    "Corresponding latex table:\n",
    "\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Model Comparison} & \\textbf{T-Statistic} & \\textbf{P-Value} \\\\ \\hline\n",
    "Logistic Regression vs SVM & 6.581 & 0.00276 \\\\ \\hline\n",
    "% Add more rows for other model comparisons if you have them\n",
    "% Example: Model A vs Model B & T-Statistic Value & P-Value \\\\\n",
    "\\end{tabular}\n",
    "\\caption{Paired T-Test Results Between Models}\n",
    "\\label{tab:my_label}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e68764",
   "metadata": {},
   "source": [
    "In summary, this result indicates that Logistic Regression is not only performing better than SVM on average, but that this better performance is statistically significant and not likely due to random chance or variability in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
