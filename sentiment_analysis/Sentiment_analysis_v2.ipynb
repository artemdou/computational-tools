{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f894ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92acf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2405cd",
   "metadata": {},
   "source": [
    "### Lyric preprocessing & Sentiment annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc2234",
   "metadata": {},
   "source": [
    "Read data from local csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a16cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"songs_with_lyrics_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70926a81",
   "metadata": {},
   "source": [
    "Clean lyrics from the following:\n",
    "* \\n\n",
    "* [something]\n",
    "\n",
    "Also explored invalid urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da130194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics):\n",
    "    # Remove text within brackets\n",
    "    cleaned_lyrics = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \"\", lyrics)\n",
    "\n",
    "    # Capitalize the first letter of each line\n",
    "    cleaned_lyrics = cleaned_lyrics.replace('\\n', \" \")\n",
    "    cleaned_lyrics = cleaned_lyrics.strip(\" \")\n",
    "\n",
    "    return cleaned_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8d39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to your DataFrame\n",
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c57ec1",
   "metadata": {},
   "source": [
    "After data exploration, we realize that some extra and more custom cleaning is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2da8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this url is not the url of a song\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Scopey-almost-every-album-ive-listened-to-lyrics'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Hossein-amini-drive-annotated'].index, inplace = True)\n",
    "df.drop(df.loc[df['lyrics_url'] == 'https://genius.com/Genius-valentines-day-playlists-lyrics'].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c2fa3",
   "metadata": {},
   "source": [
    "Label songs based on their lyric sentiments.\n",
    "\n",
    "Used textblob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47ba208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sentiment analysis using TextBlob\n",
    "def get_sentiment(lyrics):\n",
    "    try:\n",
    "        blob = TextBlob(lyrics)\n",
    "        # TextBlob returns polarity and subjectivity, you can use just polarity for a simple positive/negative/neutral sentiment\n",
    "        polarity = blob.sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            return \"Positive\"\n",
    "        elif polarity < 0:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing lyrics: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_lyrics(lyric):\n",
    "    cleaned_lyrics = re.sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc6303e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.7 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['sentiment'] = df['lyrics'].apply(lambda lyrics: get_sentiment(lyrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aab5e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>playlist</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10034</th>\n",
       "      <td>1CYBnHYYbOAsuDCGa0zrw0</td>\n",
       "      <td>Without a Light</td>\n",
       "      <td>4RwbDag6jWIYJnEGH6Wte9</td>\n",
       "      <td>Drew Holcomb &amp; The Neighbors</td>\n",
       "      <td>64</td>\n",
       "      <td>['37i9dQZF1DX9crXQ0wuuXE']</td>\n",
       "      <td>https://genius.com/Drew-holcomb-and-the-neighb...</td>\n",
       "      <td>Stay a while Maybe I will find the words to sa...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>2Dct3GykKZ58hpWRFfe2Qd</td>\n",
       "      <td>Heading South</td>\n",
       "      <td>40ZNYROS4zLfyyBSs2PGe2</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>85</td>\n",
       "      <td>['37i9dQZF1DX7aUUBCKwo4Y', '37i9dQZF1DX13ZzXoo...</td>\n",
       "      <td>https://genius.com/Zach-bryan-heading-south-ly...</td>\n",
       "      <td>Was a boy who was a dreamer and he flew so hig...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>7xNQMVeEgXQf0xUsTlcpMP</td>\n",
       "      <td>Made to Love You</td>\n",
       "      <td>3wrdNgjTSLLQZ382sPyoA5</td>\n",
       "      <td>Dan Owen</td>\n",
       "      <td>53</td>\n",
       "      <td>['37i9dQZF1DWXxauMBOQPxX']</td>\n",
       "      <td>https://genius.com/Dan-owen-made-to-love-you-l...</td>\n",
       "      <td>I never thought it could be And there was noth...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>6gHzcDHbcoGgvoGAtcTq94</td>\n",
       "      <td>Eric After Hours Blues</td>\n",
       "      <td>6PAt558ZEZl0DmdXlnjMgD</td>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>34</td>\n",
       "      <td>['37i9dQZF1DX9tJFUKjeDqu', '3a54WQYSUPwjgGmfd4...</td>\n",
       "      <td>https://genius.com/Scipio-kurupt-welcome-2-la-...</td>\n",
       "      <td>Welcome to LA  Welcome to LA Welcome to LA  We...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>1Az0fhiWi0EVS4cZ3FF20X</td>\n",
       "      <td>Sometimes It Snows in April</td>\n",
       "      <td>5a2EaR3hamoenG9rDuVn8j</td>\n",
       "      <td>Prince</td>\n",
       "      <td>49</td>\n",
       "      <td>['5qwDfhyhvk4fr5XZEDRpWc']</td>\n",
       "      <td>https://genius.com/Prince-and-the-revolution-s...</td>\n",
       "      <td>Tracy died soon  after a long fought civil war...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>3kSXn1osC89W8JcPLozTzs</td>\n",
       "      <td>Stand By You</td>\n",
       "      <td>3QLIkT4rD2FMusaqmkepbq</td>\n",
       "      <td>Rachel Platten</td>\n",
       "      <td>66</td>\n",
       "      <td>['37i9dQZF1DX0KGZxcPEEqa', '4zihGV0dKifyihlMLs...</td>\n",
       "      <td>https://genius.com/Rachel-platten-stand-by-you...</td>\n",
       "      <td>Even if we can't find Heaven, Heaven, Heaven H...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>5hRyy1AIJMc5wyizJcSIEa</td>\n",
       "      <td>Got Your Name On It</td>\n",
       "      <td>2nTzAHwCk0swkDdIPj2FIP</td>\n",
       "      <td>Jade Eagleson</td>\n",
       "      <td>54</td>\n",
       "      <td>['4QdmaN439k41ihsIw7B9r3']</td>\n",
       "      <td>https://genius.com/Jade-eagleson-got-your-name...</td>\n",
       "      <td>There's a spot in my driveway Where you can pa...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>7mitXLIMCflkhZiD34uEQI</td>\n",
       "      <td>Party Rock Anthem</td>\n",
       "      <td>3sgFRtyBnxXD5ESfmbK4dl</td>\n",
       "      <td>LMFAO</td>\n",
       "      <td>76</td>\n",
       "      <td>['6vJy4OUcFt0akV2QE9kAx1', '7og4tbbFFTkB7FW205...</td>\n",
       "      <td>https://genius.com/Lmfao-party-rock-anthem-lyrics</td>\n",
       "      <td>Party Rock Yeah Woo! Let's go!  Party rock is ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>2hPyG7NMpHAmOrmlSziAx2</td>\n",
       "      <td>Farther Up The Road</td>\n",
       "      <td>48nwxUvPJZkm8uPa7xMzmj</td>\n",
       "      <td>Bobby \"Blue\" Bland</td>\n",
       "      <td>39</td>\n",
       "      <td>['37i9dQZF1DXcu3QLJudo4X']</td>\n",
       "      <td>https://genius.com/Bobby-blue-bland-farther-up...</td>\n",
       "      <td>Further on up the road, someone gonna hurt you...</td>\n",
       "      <td>en</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>5TvE3pk05pyFIGdSY9j4DJ</td>\n",
       "      <td>Say Something</td>\n",
       "      <td>5xKp3UyavIBUsGy3DQdXeF</td>\n",
       "      <td>A Great Big World</td>\n",
       "      <td>72</td>\n",
       "      <td>['6ZAg4XZOoHgt5AWwuat8Kk', '3B1yxHl5pbyORZ9bjW...</td>\n",
       "      <td>https://genius.com/A-great-big-world-and-chris...</td>\n",
       "      <td>Say something, I'm giving up on you I'll be th...</td>\n",
       "      <td>en</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      song_id                    song_name  \\\n",
       "10034  1CYBnHYYbOAsuDCGa0zrw0              Without a Light   \n",
       "3286   2Dct3GykKZ58hpWRFfe2Qd                Heading South   \n",
       "5079   7xNQMVeEgXQf0xUsTlcpMP             Made to Love You   \n",
       "2337   6gHzcDHbcoGgvoGAtcTq94       Eric After Hours Blues   \n",
       "7523   1Az0fhiWi0EVS4cZ3FF20X  Sometimes It Snows in April   \n",
       "7667   3kSXn1osC89W8JcPLozTzs                 Stand By You   \n",
       "3111   5hRyy1AIJMc5wyizJcSIEa          Got Your Name On It   \n",
       "6284   7mitXLIMCflkhZiD34uEQI            Party Rock Anthem   \n",
       "2527   2hPyG7NMpHAmOrmlSziAx2          Farther Up The Road   \n",
       "6996   5TvE3pk05pyFIGdSY9j4DJ                Say Something   \n",
       "\n",
       "                    artist_id                   artist_name  popularity  \\\n",
       "10034  4RwbDag6jWIYJnEGH6Wte9  Drew Holcomb & The Neighbors          64   \n",
       "3286   40ZNYROS4zLfyyBSs2PGe2                    Zach Bryan          85   \n",
       "5079   3wrdNgjTSLLQZ382sPyoA5                      Dan Owen          53   \n",
       "2337   6PAt558ZEZl0DmdXlnjMgD                  Eric Clapton          34   \n",
       "7523   5a2EaR3hamoenG9rDuVn8j                        Prince          49   \n",
       "7667   3QLIkT4rD2FMusaqmkepbq                Rachel Platten          66   \n",
       "3111   2nTzAHwCk0swkDdIPj2FIP                 Jade Eagleson          54   \n",
       "6284   3sgFRtyBnxXD5ESfmbK4dl                         LMFAO          76   \n",
       "2527   48nwxUvPJZkm8uPa7xMzmj            Bobby \"Blue\" Bland          39   \n",
       "6996   5xKp3UyavIBUsGy3DQdXeF             A Great Big World          72   \n",
       "\n",
       "                                                playlist  \\\n",
       "10034                         ['37i9dQZF1DX9crXQ0wuuXE']   \n",
       "3286   ['37i9dQZF1DX7aUUBCKwo4Y', '37i9dQZF1DX13ZzXoo...   \n",
       "5079                          ['37i9dQZF1DWXxauMBOQPxX']   \n",
       "2337   ['37i9dQZF1DX9tJFUKjeDqu', '3a54WQYSUPwjgGmfd4...   \n",
       "7523                          ['5qwDfhyhvk4fr5XZEDRpWc']   \n",
       "7667   ['37i9dQZF1DX0KGZxcPEEqa', '4zihGV0dKifyihlMLs...   \n",
       "3111                          ['4QdmaN439k41ihsIw7B9r3']   \n",
       "6284   ['6vJy4OUcFt0akV2QE9kAx1', '7og4tbbFFTkB7FW205...   \n",
       "2527                          ['37i9dQZF1DXcu3QLJudo4X']   \n",
       "6996   ['6ZAg4XZOoHgt5AWwuat8Kk', '3B1yxHl5pbyORZ9bjW...   \n",
       "\n",
       "                                              lyrics_url  \\\n",
       "10034  https://genius.com/Drew-holcomb-and-the-neighb...   \n",
       "3286   https://genius.com/Zach-bryan-heading-south-ly...   \n",
       "5079   https://genius.com/Dan-owen-made-to-love-you-l...   \n",
       "2337   https://genius.com/Scipio-kurupt-welcome-2-la-...   \n",
       "7523   https://genius.com/Prince-and-the-revolution-s...   \n",
       "7667   https://genius.com/Rachel-platten-stand-by-you...   \n",
       "3111   https://genius.com/Jade-eagleson-got-your-name...   \n",
       "6284   https://genius.com/Lmfao-party-rock-anthem-lyrics   \n",
       "2527   https://genius.com/Bobby-blue-bland-farther-up...   \n",
       "6996   https://genius.com/A-great-big-world-and-chris...   \n",
       "\n",
       "                                                  lyrics language sentiment  \n",
       "10034  Stay a while Maybe I will find the words to sa...       en  Positive  \n",
       "3286   Was a boy who was a dreamer and he flew so hig...       en  Positive  \n",
       "5079   I never thought it could be And there was noth...       en  Positive  \n",
       "2337   Welcome to LA  Welcome to LA Welcome to LA  We...       en  Positive  \n",
       "7523   Tracy died soon  after a long fought civil war...       en  Positive  \n",
       "7667   Even if we can't find Heaven, Heaven, Heaven H...       en  Positive  \n",
       "3111   There's a spot in my driveway Where you can pa...       en  Positive  \n",
       "6284   Party Rock Yeah Woo! Let's go!  Party rock is ...       en  Positive  \n",
       "2527   Further on up the road, someone gonna hurt you...       en  Positive  \n",
       "6996   Say something, I'm giving up on you I'll be th...       en  Negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c1d50",
   "metadata": {},
   "source": [
    "#### Lyric descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2beec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyric descriptives\n",
      "--------------------------\n",
      "Number of songs: 10514\n",
      "Average number of characters in a song's lyrics: 1895.2707818147233\n",
      "Average number of words in a song's lyrics: 376.53671295415637\n"
     ]
    }
   ],
   "source": [
    "rows = len(df)\n",
    "average_length = df['lyrics'].str.len().mean()\n",
    "average_words = df['lyrics'].apply(lambda x: len(x.split())).mean()\n",
    "print(\"Lyric descriptives\")\n",
    "print(\"--------------------------\")\n",
    "print(f\"Number of songs: {rows}\")\n",
    "print(f\"Average number of characters in a song's lyrics: {average_length}\")\n",
    "print(f\"Average number of words in a song's lyrics: {average_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e48745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.12992200875024%\n",
      "Precentage of positive labels: 67.26269735590641%\n",
      "Precentage of neutral labels: 1.6073806353433517%\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df[df['sentiment']=='Negative'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df[df['sentiment']=='Positive'])/len(df) * 100}%\")\n",
    "print(f\"Precentage of neutral labels: {len(df[df['sentiment']=='Neutral'])/len(df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b2bf1d",
   "metadata": {},
   "source": [
    "### Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d128cf",
   "metadata": {},
   "source": [
    "#### Balancing our dataset & vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a927f",
   "metadata": {},
   "source": [
    "Since the neutral reviews are so few there is no point in keeping them in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed88146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_pos = df[df['sentiment'] !='Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa3eabe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dataset Distribution\n",
      "---------------------\n",
      "Precentage of negative labels: 31.6384726921218%\n",
      "Precentage of positive labels: 68.3615273078782%\n"
     ]
    }
   ],
   "source": [
    "print(\"New Dataset Distribution\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Precentage of negative labels: {len(df_neg_pos[df_neg_pos['sentiment']=='Negative'])/len(df_neg_pos) * 100}%\")\n",
    "print(f\"Precentage of positive labels: {len(df_neg_pos[df_neg_pos['sentiment']=='Positive'])/len(df_neg_pos) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814f7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_neg_pos['sentiment'])\n",
    "\n",
    "# Preprocessing with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df_neg_pos['lyrics'])\n",
    "y = y_encoded\n",
    "\n",
    "# Split your data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply undersampling to the training data\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed702783",
   "metadata": {},
   "source": [
    "**Algorithm selection**\n",
    "\n",
    "We keep in mind the computational resources needed for the algorithms. Maybe we don't end up with the stringest model, but we aim for the most feasibly reliable one.\n",
    "\n",
    "| Algorithm | Pros | Cons |\n",
    "|-----------|------|------|\n",
    "| **SVM (Support Vector Machine)** | - Effective in high-dimensional spaces<br> - Works well with a clear margin of separation<br> - Less prone to overfitting | - Not suitable for very large datasets<br> - Requires feature scaling<br> - Can be less effective with overlapping classes |\n",
    "| **Naive Bayes** | - Fast and efficient<br> - Works well with high-dimensional data<br> - Effective for text classification | - Based on the assumption of feature independence<br> - Can be outperformed by more complex models |\n",
    "| **Logistic Regression** | - Simple and easy to implement<br> - Efficient for binary classification tasks<br> - Provides probabilities for outcomes | - Can struggle with complex relationships in data<br> - Not the best choice for non-linear problems |\n",
    "| **Random Forest** | - Handles non-linear data well<br> - Less prone to overfitting<br> - Good for classification and regression | - Can be slow on large datasets<br> - Model interpretability can be challenging |\n",
    "| **LSTM (Long Short-Term Memory)** | - Excellent for sequence data like text<br> - Can capture long-term dependencies<br> - Good for complex language modeling | - Computationally intensive<br> - Requires large training datasets<br> - Longer training times |\n",
    "| **BERT (Bidirectional Encoder Representations from Transformers)** | - State-of-the-art for NLP tasks<br> - Understands word context and nuances<br> - Highly accurate for various language tasks | - Requires significant computational resources<br> - Complex and requires fine-tuning<br> - Overkill for simpler tasks |\n",
    "\n",
    "\n",
    "**SVM, Naive Bayes, Logistic Regression, and Random Forest**: These are traditional machine learning models and are generally less complex and computationally intensive compared to LSTM and BERT. They can be effective for smaller datasets or less complex sentiment analysis tasks but might not capture the intricacies of language as effectively as LSTM or BERT.\n",
    "\n",
    "**LSTM and BERT**: These are advanced deep learning models that excel in understanding language context and complexities. They are more suitable for large datasets and complex NLP tasks, but their need for significant computational resources and longer training times can be a drawback, especially in resource-constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930dd94",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279f17",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "543826e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 28.4 s\n",
      "Wall time: 6min 19s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5569b75",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6e27b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score: 0.8016125578734175\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and best score\n",
    "svm_best_parameters = grid_search.best_params_\n",
    "svm_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", svm_best_parameters)\n",
    "print(\"Best Score:\", svm_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8d68b",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfdccf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8144030932817786\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_search.best_estimator_\n",
    "test_accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cfc9e",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420733cf",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060857ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 240 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.1, 1, 10, 100]}, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100]}, verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Define the parameter grid\n",
    "# Naive Bayes usually has fewer hyperparameters to tune, but you can experiment with alpha\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100]  # Additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(nb_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0973a",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8fd08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 1}\n",
      "Best Score: 0.7013873824542189\n"
     ]
    }
   ],
   "source": [
    "nb_best_parameters = grid_search.best_params_\n",
    "nb_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", nb_best_parameters)\n",
    "print(\"Best Score:\", nb_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387e5fb",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d2da47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7414209763170614\n"
     ]
    }
   ],
   "source": [
    "best_nb = grid_search.best_estimator_\n",
    "test_accuracy = best_nb.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7cae7",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b00dc",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d04a361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "CPU times: total: 688 ms\n",
      "Wall time: 7.39 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Algorithm to use in optimization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b9228",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504f6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'solver': 'saga'}\n",
      "Best Score: 0.8122904008227765\n"
     ]
    }
   ],
   "source": [
    "lr_best_parameters = grid_search.best_params_\n",
    "lr_best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", lr_best_parameters)\n",
    "print(\"Best Score:\", lr_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3faede",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9576bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8231029482841953\n"
     ]
    }
   ],
   "source": [
    "best_lr = grid_search.best_estimator_\n",
    "test_accuracy = best_lr.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16d183",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de2aab",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "832dc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "#     'max_depth': [10, 20, 30, None],  # Maximum depth of the tree\n",
    "#     'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required to be at a leaf node\n",
    "# }\n",
    "\n",
    "# # Grid search with cross-validation\n",
    "# grid_search = GridSearchCV(rf_model, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da475185",
   "metadata": {},
   "source": [
    "Best parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff95b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters and best score\n",
    "# forest_best_parameters = grid_search.best_params_\n",
    "# forest_best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Parameters:\", forest_best_parameters)\n",
    "# print(\"Best Score:\", forest_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06c386",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0643dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate on test data (optional)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "# test_accuracy = best_rf.score(X_test, y_test)\n",
    "# print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b16ee0",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb4615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of all the models\n",
    "best_estimators = {\n",
    "    'SVM': best_svm,\n",
    "    'Naive Bayes': best_nb,\n",
    "    'Logistic Regression': best_lr,\n",
    "#     'Random Forest': best_rf\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c277928",
   "metadata": {},
   "source": [
    "Dummy classifier as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53c365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# Implement the Dummy Classifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "\n",
    "# Add the Dummy Classifier to your best estimators dictionary\n",
    "best_estimators['Dummy Classifier'] = dummy_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51106e",
   "metadata": {},
   "source": [
    "#### Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "debcbd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.8144030932817786, Precision: 0.8366713244592203, Recall: 0.8144030932817786, F1 Score: 0.8200886257226082\n",
      "Naive Bayes - Accuracy: 0.7414209763170614, Precision: 0.7493681326869763, Recall: 0.7414209763170614, F1 Score: 0.7447846190703241\n",
      "Logistic Regression - Accuracy: 0.8231029482841953, Precision: 0.8419559537515556, Recall: 0.8231029482841953, F1 Score: 0.8281002651608682\n",
      "Dummy Classifier - Accuracy: 0.7080715321411309, Precision: 0.5013652946286886, Recall: 0.7080715321411309, F1 Score: 0.5870542131221035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for all models\n",
    "predictions = {model: estimator.predict(X_test) for model, estimator in best_estimators.items()}\n",
    "\n",
    "# Initialize a dictionary to hold the metrics\n",
    "metrics_summary = {}\n",
    "\n",
    "# Calculate metrics for all models\n",
    "for model, model_predictions in predictions.items():\n",
    "    accuracy = accuracy_score(y_test, model_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, model_predictions, average='weighted')\n",
    "    metrics_summary[model] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# Display the metrics for each model including the Dummy Classifier\n",
    "for model, metrics in metrics_summary.items():\n",
    "    print(f\"{model} - Accuracy: {metrics['Accuracy']}, Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b5177",
   "metadata": {},
   "source": [
    "Metrict table to be copy pasted into overleaf to save time <3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ae2ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & Accuracy & Precision & Recall & F1 Score \\\\\n",
      "\\midrule\n",
      "SVM & 0.81 & 0.84 & 0.81 & 0.82 \\\\\n",
      "Naive Bayes & 0.74 & 0.75 & 0.74 & 0.74 \\\\\n",
      "Logistic Regression & 0.82 & 0.84 & 0.82 & 0.83 \\\\\n",
      "Dummy Classifier & 0.71 & 0.50 & 0.71 & 0.59 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert metrics_summary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_summary).transpose()\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = metrics_df.to_latex(float_format=\"%.2f\", header=True, index=True)\n",
    "\n",
    "# Printing the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40779bb2",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "**Results from Undersampled Models**\n",
    "\n",
    "*SVM (Support Vector Machine)*:\n",
    "\n",
    "Accuracy: 81.44% - A good percentage of the predictions are correct.\n",
    "Precision: 83.67% - When it predicts a label, it is correct about 83.67% of the time.\n",
    "Recall: 81.44% - It correctly identifies 81.44% of all true positive and negative instances.\n",
    "F1 Score: 82.01% - A balance between precision and recall, indicating good overall performance.\n",
    "\n",
    "*Naive Bayes*:\n",
    "\n",
    "Accuracy: 74.14% - Lower than SVM and Logistic Regression.\n",
    "Precision: 74.94% - Slightly higher precision compared to its accuracy.\n",
    "Recall: 74.14% - Similar to accuracy, indicating consistent performance across classes.\n",
    "F1 Score: 74.48% - Reflects a balance between precision and recall.\n",
    "\n",
    "*Logistic Regression*:\n",
    "\n",
    "Accuracy: 82.31% - The highest among the models.\n",
    "Precision: 84.20% - Indicates a strong ability to correctly label positive and negative instances.\n",
    "Recall: 82.31% - Consistent with its accuracy.\n",
    "F1 Score: 82.81% - Shows a good balance between precision and recall.\n",
    "\n",
    "*Dummy Classifier*:\n",
    "\n",
    "Accuracy: 70.81% - As a baseline, it's predictably lower but not by a wide margin.\n",
    "Precision: 50.14% - Low precision indicates a high number of false positives.\n",
    "Recall: 70.81% - Identical to accuracy, expected for a model predicting the most frequent class.\n",
    "F1 Score: 58.71% - Lower, reflecting the imbalance between precision and recall.\n",
    "\n",
    "**Interpretation and Comparison**\n",
    "\n",
    "Improved Balanced Performance: The SVM and Logistic Regression models show an overall balanced performance in terms of accuracy, precision, recall, and F1 score. This suggests effective handling of both positive and negative classes after undersampling.\n",
    "\n",
    "Logistic Regression's Superiority: Logistic Regression slightly outperforms SVM in all metrics, making it potentially the best model among those tested.\n",
    "\n",
    "Naive Bayes' Lower Performance: Naive Bayes lags behind SVM and Logistic Regression, indicating it might be less suited for this particular task or data distribution.\n",
    "\n",
    "Dummy Classifier as Baseline: The Dummy Classifier serves as a baseline, and its lower performance compared to other models \n",
    "validates their effectiveness.\n",
    "\n",
    "Effect of Undersampling: The improved balance in precision and recall in the SVM and Logistic Regression models compared to the Dummy Classifier suggests that undersampling helped in addressing the class imbalance issue.\n",
    "Comparison with Initial Attempt: If these results show an improvement over your initial attempt without sampling, it indicates that addressing the class imbalance was beneficial. Specifically, look for improvements in precision and recall for the minority class, which are often most affected by class imbalance.\n",
    "\n",
    "In summary, undersampling appears to have helped in balancing the performance of your models across different metrics, with Logistic Regression showing the best overall performance. These models now likely offer a more reliable understanding of their ability to generalize to new data, particularly in a more balanced real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ebab9",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0a8b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mislabeling percentages for SVM:\n",
      "Label negative: 17.88% mislabeled\n",
      "Label positive: 18.84% mislabeled\n",
      "\n",
      "Mislabeling percentages for Naive Bayes:\n",
      "Label negative: 39.40% mislabeled\n",
      "Label positive: 20.27% mislabeled\n",
      "\n",
      "Mislabeling percentages for Logistic Regression:\n",
      "Label negative: 17.88% mislabeled\n",
      "Label positive: 17.61% mislabeled\n",
      "\n",
      "Mislabeling percentages for Dummy Classifier:\n",
      "Label negative: 100.00% mislabeled\n",
      "Label positive: 0.00% mislabeled\n"
     ]
    }
   ],
   "source": [
    "# Mapping for your labels\n",
    "label_mapping = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # Generate the confusion matrix for the current model\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calculate the mislabeling percentage for each label\n",
    "    mislabeling_percentages = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    mislabeling_percentages = mislabeling_percentages / np.sum(cm, axis=1) * 100\n",
    "\n",
    "    print(f\"\\nMislabeling percentages for {model_name}:\")\n",
    "    for label_idx, mislabel_pct in enumerate(mislabeling_percentages):\n",
    "        label_name = label_mapping.get(label_idx, f\"Label {label_idx}\")\n",
    "        print(f\"Label {label_name}: {mislabel_pct:.2f}% mislabeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c28d1",
   "metadata": {},
   "source": [
    "The adjustments made to balance the classes have led to a more equitable performance between the negative and positive labels. Previously, the models were more biased towards correctly identifying the positive (majority) class, while the negative (minority) class saw higher rates of mislabeling. The balanced approach has notably improved the ability of models, especially Naive Bayes and SVM, to correctly classify the negative instances, leading to a more reliable and fair performance across classes.\n",
    "\n",
    "This analysis underscores the importance of addressing class imbalance in datasets, especially when dealing with models that are sensitive to such disparities. It highlights how balancing techniques can lead to a more accurate and unbiased assessment of a model's predictive capabilities.\n",
    "\n",
    "**Comparison with Imbalanced Results**\n",
    "1. Improved Balance: The balanced models show a more even performance between the negative and positive classes. The imbalanced dataset had a tendency for lower mislabeling in the positive class (the majority class) and higher mislabeling in the negative class.\n",
    "2. Overall Improvement: In the balanced dataset, all models (except for the Dummy Classifier) show a reduced mislabeling rate for the negative class, indicating that balancing the dataset has improved their ability to correctly identify negative instances.\n",
    "3. Consistent Performance in Positive Class: The performance in identifying positive labels remains relatively good and more balanced after undersampling, as seen in the reduced mislabeling rates for SVM and Logistic Regression.\n",
    "4. Naive Bayes: This model shows the most significant improvement in the negative class, indicating that the balancing had a notable positive effect on its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e89940",
   "metadata": {},
   "source": [
    "#### Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02705f85",
   "metadata": {},
   "source": [
    "We are conducting further statistical testing between our two top persorming models.\n",
    "\n",
    "First we are conducting a Shapiro-Wilk test with H0: \"Differences between the two models' scores seem to be normally distributed (fail to reject H0)\". If we failt to reject H0 then we can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92c27391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences seem to be normally distributed (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Obtain cross-validation scores for each model\n",
    "scores_lr = cross_val_score(best_lr, X_tfidf, y, cv=5)\n",
    "scores_svm = cross_val_score(best_svm, X_tfidf, y, cv=5)\n",
    "\n",
    "# Calculate differences between sets of scores\n",
    "score_diffs = scores_lr - scores_svm\n",
    "\n",
    "# Shapiro-Wilk Test for Normality\n",
    "stat, p = shapiro(score_diffs)\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Differences seem to be normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('Differences do not appear to be normally distributed (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2409a7",
   "metadata": {},
   "source": [
    "Interpreting the Shapiro-Wilk test result \"Differences seem to be normally distributed (fail to reject H0)\" in the context of comparing your best_lr (Logistic Regression) and best_svm (Support Vector Machine) models indicates that the differences in their cross-validation scores do not significantly deviate from a normal distribution. This means you can proceed with the paired t-test for these models, as the normality assumption required for the paired t-test is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d246241",
   "metadata": {},
   "source": [
    "Now let's perform a paired t-test to determine if the differences in performance between the models are statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd85f4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired t-test between Logistic Regression and SVM:\n",
      "T-statistic: 6.491434997263605, P-value: 0.002904180302547974\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_rel(scores_lr, scores_svm)\n",
    "\n",
    "print(f\"Paired t-test between Logistic Regression and SVM:\\nT-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00383e44",
   "metadata": {},
   "source": [
    "**Statistical Significance**: Since the p-value is less than the typical alpha level of 0.05, you can reject the null hypothesis. This means that the difference in performance between the Logistic Regression and SVM models is statistically significant.\n",
    "\n",
    "**Model Comparison**: The positive t-statistic suggests that the mean cross-validation score of the Logistic Regression model is higher than that of the SVM model. This indicates that Logistic Regression performs better than SVM on your dataset, and the difference in their performances is not just due to random chance.\n",
    "\n",
    "\n",
    "In summary, this result suggests that Logistic Regression not only performs better than SVM on average but that this better performance is statistically significant and unlikely to be due to random fluctuations in the dataset. This provides a solid basis for preferring Logistic Regression over SVM in this particular case, assuming the other factors like model interpretability, complexity, and computational requirements also align with your project's needs.\n",
    "\n",
    "------------------------\n",
    "Corresponding latex table:\n",
    "\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Model Comparison} & \\textbf{T-Statistic} & \\textbf{P-Value} \\\\ \\hline\n",
    "Logistic Regression vs SVM & 6.491 & 0.0029 \\\\ \\hline\n",
    "\\end{tabular}\n",
    "\\caption{Paired T-Test Results Between Logistic Regression and SVM}\n",
    "\\label{tab:paired_t_test}\n",
    "\\end{table}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e68764",
   "metadata": {},
   "source": [
    "In summary, this result indicates that Logistic Regression is not only performing better than SVM on average, but that this better performance is statistically significant and not likely due to random chance or variability in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
